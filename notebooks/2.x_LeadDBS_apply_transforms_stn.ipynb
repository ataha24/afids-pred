{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae53d91-bf4f-424a-b3c3-d4ac6faaad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def apply_affine_transform(mat_path, fcsv_path):\n",
    "    \"\"\"\n",
    "    Applies a transformation from a .mat file to coordinates in a .fcsv file\n",
    "    \n",
    "    Parameters:\n",
    "    - fcsv_path: str, path to the .fcsv file with coordinates\n",
    "    - mat_path: str, path to the .mat file with the transformation matrix\n",
    "    - output_path: str, path to save the transformed coordinates file\n",
    "    \n",
    "    Returns:\n",
    "    - None, saves the transformed coordinates to the specified output path\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the .mat file\n",
    "    mat_contents = scipy.io.loadmat(mat_path)\n",
    "    \n",
    "    # Extract the transformation matrix\n",
    "    transformation_matrix = mat_contents['tmat']\n",
    "    \n",
    "    # Read the .fcsv file with correct delimiter and header handling\n",
    "    fcsv_data = pd.read_csv(fcsv_path, delimiter=',', header=2)  # Skipping first two lines which are presets (Assuming all coordinates are in RAS)\n",
    "    \n",
    "    # Extract the coordinates\n",
    "    coordinates = fcsv_data[['x', 'y', 'z']].values\n",
    "    \n",
    "    # Convert the 3D coordinates to homogeneous coordinates\n",
    "    homogeneous_coordinates = np.hstack((coordinates, np.ones((coordinates.shape[0], 1))))\n",
    "    \n",
    "    # Apply the 4x4 transformation matrix to the homogeneous coordinates\n",
    "    transformed_homogeneous_coordinates = (np.linalg.inv(transformation_matrix) @ homogeneous_coordinates.T).T\n",
    "    \n",
    "    # Convert back to 3D coordinates by discarding the homogeneous component\n",
    "    transformed_coordinates = transformed_homogeneous_coordinates[:, :3]\n",
    "    \n",
    "    return transformed_coordinates\n",
    "\n",
    "def apply_warp_deformation(transform_path, fiducial_file):\n",
    "    \"\"\"\n",
    "    Transforms fiducial points from a fiducial file using a transformation matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - transform_path: str, path to the transformation matrix file\n",
    "    - fiducial_file: str, path to the fiducial file\n",
    "\n",
    "    Returns:\n",
    "    - transformed_fiducial_points: list of transformed fiducial points\n",
    "    - fiducial_properties: list of properties corresponding to each fiducial point\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reads the transform and casts the output to a compatible format\n",
    "    transform_image = sitk.ReadImage(transform_path)\n",
    "    transform_image = sitk.Cast(transform_image, sitk.sitkVectorFloat64)\n",
    "\n",
    "    # Load it as a transform\n",
    "    transform = sitk.Transform(transform_image)\n",
    "\n",
    "    # Loop through the file and extract the fiducial points\n",
    "    fiducial_points = []\n",
    "    with open(fiducial_file, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            # Skip comment lines starting with '#'\n",
    "            if not line.startswith('#'):\n",
    "                # Extract the properties and coordinates from each line\n",
    "                fields = line.strip().split(',')\n",
    "                x, y, z = float(fields[1]), float(fields[2]), float(fields[3])\n",
    "                fiducial_points.append([x, y, z])\n",
    "\n",
    "    fiducial_points = np.array(fiducial_points) * np.array([-1, -1, 1])\n",
    "\n",
    "    # Apply the transform to the fiducial points\n",
    "    transformed_fiducial_points = []\n",
    "    for point in fiducial_points:\n",
    "        transformed_point = transform.TransformPoint(point.tolist())\n",
    "        transformed_fiducial_points.append(transformed_point)\n",
    "\n",
    "    transformed_fiducial_points = np.array(transformed_fiducial_points) * np.array([-1, -1, 1])\n",
    "\n",
    "    return transformed_fiducial_points\n",
    "\n",
    "\n",
    "def coords_to_fcsv(coords_array, fcsv_output):\n",
    "    fcsv = [\n",
    "         '# Markups fiducial file version = 4.10',\n",
    "         '# CoordinateSystem = RAS',\n",
    "         '# columns = id,x,y,z,ow,ox,oy,oz,vis,sel,lock,label,desc,associatedNodeID',\n",
    "         '1,afid1_x,afid1_y,afid1_z,0,0,0,1,1,1,1,1,Right STN,vtkMRMLScalarVolumeNode1',\n",
    "         '2,afid2_x,afid2_y,afid2_z,0,0,0,1,1,1,1,2,Left STN ,vtkMRMLScalarVolumeNode1'\n",
    "    ]\n",
    "\n",
    "    # Loop over fiducials\n",
    "    for fid in range(1, coords_array.shape[0]+1):\n",
    "        # Update fcsv, skipping header\n",
    "        line_idx = fid + 2\n",
    "        centroid_idx = fid - 1\n",
    "        fcsv[line_idx] = fcsv[line_idx].replace(\n",
    "            f\"afid{fid}_x\", str(coords_array[centroid_idx][0])\n",
    "        )\n",
    "        fcsv[line_idx] = fcsv[line_idx].replace(\n",
    "            f\"afid{fid}_y\", str(coords_array[centroid_idx][1])\n",
    "        )\n",
    "        fcsv[line_idx] = fcsv[line_idx].replace(\n",
    "            f\"afid{fid}_z\", str(coords_array[centroid_idx][2])\n",
    "        )\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    create_folder(os.path.dirname(fcsv_output))\n",
    "    # Write output fcsv\n",
    "    with open(fcsv_output, \"w\") as f:\n",
    "        f.write(\"\\n\".join(line for line in fcsv))\n",
    "        \n",
    "        \n",
    "def create_folder(path):\n",
    "    try:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        print(f\"Directory '{path}' created successfully.\")\n",
    "    except OSError as error:\n",
    "        print(f\"Error creating directory '{path}': {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adfbe8d-cc66-4a0a-9a5f-63dfd0e905b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['sub-P009', 'sub-P036', 'sub-P039', 'sub-P006', 'sub-P041', 'sub-P093', 'sub-P016', 'sub-P027', 'sub-P019', 'sub-P017']\n",
      "sub-P009\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P036\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P039\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P006\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P041\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P093\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P016\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P027\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P019\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P017\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n"
     ]
    }
   ],
   "source": [
    "ANALYSES = ['leaddbs'] #multiple renamed leaddbs derivative folders; each is using different images for registration \n",
    "\n",
    "BASE_DIR = '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/derivatives'\n",
    "\n",
    "for ANALYSIS in ANALYSES:\n",
    "    \n",
    "    SUBJECT_IDS = [subject for subject in os.listdir(f'{BASE_DIR}/{ANALYSIS}') if \"sub-\" in subject]\n",
    "\n",
    "    print(len(SUBJECT_IDS),SUBJECT_IDS)\n",
    "\n",
    "    for subject in SUBJECT_IDS:\n",
    "        print(subject)\n",
    "\n",
    "        transform_affine_path = f'{BASE_DIR}/{ANALYSIS}/{subject}/coregistration/transformations/{subject}_from-axT2w_to-anchorNative_desc-spm.mat' #specify moving to fixed bc function inverts the matrix\n",
    "        transform_warp_path = f'{BASE_DIR}/{ANALYSIS}/{subject}/normalization/transformations/{subject}_from-anchorNative_to-MNI152NLin2009bAsym_desc-ants.nii.gz' #because we need to take coordinate from native space to MNI we read the inverse matrix\n",
    "        fiducial_file = f'/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids/sub-MNI152NLin2009bAsym_res-01_desc-groundtruth_stn.fcsv'\n",
    "\n",
    "        #Apply deformable\n",
    "        coord_warped = apply_warp_deformation(transform_warp_path, fiducial_file)\n",
    "        deform_fcsv = fiducial_file.replace(\"sub-MNI152NLin2009bAsym\", f\"{subject}\")\n",
    "        coords_to_fcsv(coord_warped,deform_fcsv)\n",
    "\n",
    "        #Apply anchornative to T2w\n",
    "        coord_tfm = apply_affine_transform(transform_affine_path, deform_fcsv)\n",
    "        affine_fcsv = deform_fcsv.replace(\"groundtruth\",ANALYSIS)\n",
    "        coords_to_fcsv(coord_tfm,affine_fcsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13f1682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['sub-P009', 'sub-P036', 'sub-P039', 'sub-P006', 'sub-P041', 'sub-P093', 'sub-P016', 'sub-P027', 'sub-P019', 'sub-P017']\n",
      "sub-P009\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P036\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P039\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P006\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P041\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P093\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P016\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P027\n",
      "found anchor native transformation\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P019\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n",
      "sub-P017\n",
      "Directory '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids' created successfully.\n"
     ]
    }
   ],
   "source": [
    "ANALYSES = ['leaddbs'] #multiple renamed leaddbs derivative folders; each is using different images for registration \n",
    "\n",
    "BASE_DIR = '/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/derivatives'\n",
    "\n",
    "for ANALYSIS in ANALYSES:\n",
    "    \n",
    "    SUBJECT_IDS = [subject for subject in os.listdir(f'{BASE_DIR}/{ANALYSIS}') if \"sub-\" in subject]\n",
    "\n",
    "    print(len(SUBJECT_IDS),SUBJECT_IDS)\n",
    "\n",
    "    for subject in SUBJECT_IDS:\n",
    "        print(subject)\n",
    "\n",
    "        transform_affine_path = f'{BASE_DIR}/{ANALYSIS}/{subject}/coregistration/transformations/{subject}_desc-precoreg_ax_T1w.mat' #specify moving to fixed bc function inverts the matrix\n",
    "        transform_warp_path = f'{BASE_DIR}/{ANALYSIS}/{subject}/normalization/transformations/{subject}_from-anchorNative_to-MNI152NLin2009bAsym_desc-ants.nii.gz' #because we need to take coordinate from native space to MNI we read the inverse matrix\n",
    "        fiducial_file = f'/Users/alaataha/Documents/GitHub/afid_pred_imaging/afidspredlead/out_fids/sub-MNI152NLin2009bAsym_res-01_desc-groundtruth_stn.fcsv'\n",
    "        \n",
    "        transformed_coordinates = apply_warp_deformation(transform_warp_path, fiducial_file)\n",
    "\n",
    "        if os.path.exists(transform_affine_path):\n",
    "            print(\"found anchor native transformation\")\n",
    "            # Load the .mat file\n",
    "            mat_contents = scipy.io.loadmat(transform_affine_path)\n",
    "            # Extract the transformation matrix\n",
    "            transformation_matrix = mat_contents['tmat']\n",
    "            # Convert the 3D coordinates to homogeneous coordinates\n",
    "            homogeneous_coordinates = np.hstack((transformed_coordinates, np.ones((transformed_coordinates.shape[0], 1))))\n",
    "            # Apply the 4x4 transformation matrix to the homogeneous coordinates\n",
    "            transformed_homogeneous_coordinates = (transformation_matrix @ homogeneous_coordinates.T).T\n",
    "            # Convert back to 3D coordinates by discarding the homogeneous component\n",
    "            transformed_coordinates = transformed_homogeneous_coordinates[:, :3]\n",
    "\n",
    "        deform_fcsv = fiducial_file.replace(\"sub-MNI152NLin2009bAsym\", f\"{subject}\").replace(\"groundtruth\",ANALYSIS)\n",
    "        coords_to_fcsv(transformed_coordinates,deform_fcsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83b7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
